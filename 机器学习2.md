## 逻辑回归

与线性回归的区别：

线性回归：解决线性问题，输出连续的结果。

逻辑回归：解决分类问题，输出离散的结果。

1. 二元分类：输出结果只有两种可能，线性回归无法解决这种问题

2. 假说表示：在逻辑回归中引入如下的公式，该模型的输出总是在(0,1)之间。
> 该模型的输出h表示预测值y=1的概率，h = 0.7表示预测值y=1的概率为70%<br>
> 当h > 0.5时表示y=1，否则表示y=0<br>

![逻辑回归算法1](img/逻辑回归算法1.png)

将上述公式中的 -θ^T * X 转换为z，就能得到下列图像（下图中的g(z)实际上是Sigmoid函数）：

![逻辑回归算法3](img/逻辑回归算法3.png)

3. 决策边界

在一个Sigmoid函数表达的逻辑回归算法（g(z)）中，如果像要得到预测值y=1，则z应该大于0。

如下图，当θ0 = -3时，使得z=0的这条直线就成为决策边界。

![决策边界](img/决策边界)

4. 损失函数

逻辑回归算法中的h如果使用和线性回归一样的**误差平方和**，会出现下图左边的非凸函数图像，而我们想要的是右边的函数图像：

![逻辑回归的损失函数](img/逻辑回归的损失函数.png)

